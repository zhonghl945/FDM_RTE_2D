import torch
import numpy as np
import h5py
import warnings
import os
from torch.utils.data import Dataset, DataLoader
from tqdm.auto import tqdm

from Diffusion import GaussianDiffusion3D, Unet3D

# å¿½ç•¥è­¦å‘Š
warnings.filterwarnings("ignore")
device = torch.device("cuda") if torch.cuda.is_available() else torch.device("cpu")
print(f"Using device: {device}")


class H5LazyDataset(Dataset):
    """
    ç”¨äºä»HDF5æ–‡ä»¶è¿›è¡Œæ‡’åŠ è½½çš„Datasetç±»ã€‚
    å®ƒç›´æ¥è¯»å–åŸå§‹æ•°æ®ï¼Œä¸è¿›è¡Œå½’ä¸€åŒ–ã€‚
    """

    def __init__(self, file_path, mode):
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"æ•°æ®æ–‡ä»¶æœªæ‰¾åˆ°: {file_path}")
        self.file_path = file_path
        self.mode = mode

        with h5py.File(self.file_path, 'r') as file:
            if self.mode not in file:
                raise KeyError(
                    f"ç»„ '{self.mode}' åœ¨HDF5æ–‡ä»¶ '{self.file_path}' ä¸­æœªæ‰¾åˆ°ã€‚å¯ç”¨ç»„: {list(file.keys())}")
            self._data_len = len(file[self.mode]['T'])

    def __len__(self):
        return self._data_len

    def __getitem__(self, idx):
        with h5py.File(self.file_path, 'r') as file:
            group = file[self.mode]
            t_sample = group['T'][idx]
            s_sample = group['S'][idx]

        t_sample = torch.tensor(t_sample, dtype=torch.float32)
        s_sample = torch.tensor(s_sample, dtype=torch.float32)
        return t_sample, s_sample


def get_diffusion_setup(T_shape_tuple, config, rescaler):
    """
    é…ç½®å¹¶è¿”å›æ‰©æ•£æ¨¡å‹ã€‚
    """
    unet = Unet3D(
        dim=config['dim'],
        dim_mults=config['dim_mults'],
        time_emb_dim_input=config['time_emb_dim'],
        resnet_block_groups=config['resnet_groups'],
        padding_mode=config['padding_mode']
    ).to(device)

    diffusion_model = GaussianDiffusion3D(
        model=unet,
        T_shape=T_shape_tuple,
        timesteps=config['timesteps'],
        beta_schedule=config['beta_schedule'],
        lambda_S_x0=config['lambda_S_x0'],
        freeze_indices_T=config['freeze_indices_T'],
        rescaler=rescaler,
    ).to(device)

    return diffusion_model


def get_data_and_rescaler(train_h5_path, test_h5_path, test_batch_size):
    """
    ä»è®­ç»ƒæ•°æ®è®¡ç®—rescalerï¼Œå¹¶åŠ è½½ä¸€æ‰¹åŸå§‹ï¼ˆRAWï¼‰æµ‹è¯•æ•°æ®ã€‚
    """
    global_max_abs_val = torch.tensor(0.0, dtype=torch.float32)
    chunk_size = 100

    with h5py.File(train_h5_path, 'r') as file:
        group_train = file['Train']
        t_dataset_train = group_train['T']
        s_dataset_train = group_train['S']
        N_train = len(t_dataset_train)

        for i in tqdm(range(0, N_train, chunk_size), desc="æ‰«æè®­ç»ƒæ•°æ®"):
            t_chunk = torch.from_numpy(t_dataset_train[i:i + chunk_size]).abs()
            s_chunk = torch.from_numpy(s_dataset_train[i:i + chunk_size]).abs()
            current_max = torch.max(t_chunk.max(), s_chunk.max())
            if current_max > global_max_abs_val:
                global_max_abs_val = current_max

    rescaler = global_max_abs_val
    print(f"ä»è®­ç»ƒé›†è®¡ç®—å¾—åˆ°çš„å…¨å±€ rescaler å€¼ä¸º: {rescaler.item()}\n")

    test_dataset = H5LazyDataset(file_path=test_h5_path, mode='Test')
    test_dataloader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False)

    T_test_batch, S_test_batch = next(iter(test_dataloader))

    print(f"å·²åŠ è½½ä¸€æ‰¹åŸå§‹æµ‹è¯•æ•°æ® Tï¼Œå½¢çŠ¶ä¸º: {T_test_batch.shape}")
    print(f"å·²åŠ è½½ä¸€æ‰¹åŸå§‹æµ‹è¯•æ•°æ® Sï¼Œå½¢çŠ¶ä¸º: {S_test_batch.shape}")

    return T_test_batch.to(device), S_test_batch.to(device), rescaler.to(device)


def run_3d_diffusion_test(config, train_h5_path, test_h5_path, test_batch_size, results_folder):
    """
    è¿è¡Œæµ‹è¯•æµç¨‹çš„ä¸»å‡½æ•°ã€‚
    """
    # 1. è·å–åŸå§‹æµ‹è¯•æ•°æ®å’Œrescaler
    T_test_batch, S_test_batch, rescaler = get_data_and_rescaler(train_h5_path, test_h5_path, test_batch_size)

    # 2. é…ç½®æ¨¡å‹ï¼Œå¹¶å°†rescalerä¼ å…¥
    T_shape_no_batch = T_test_batch.shape[1:]
    diffusion_model = get_diffusion_setup(T_shape_tuple=T_shape_no_batch, config=config, rescaler=rescaler)

    # 3. ç›´æ¥åŠ è½½æ¨¡å‹çŠ¶æ€ï¼Œä¸å†ä¾èµ–Trainer
    milestone = config['load_milestone']
    model_path = os.path.join(results_folder, f'model-{milestone}.pt')

    try:
        print(f"\næ­£åœ¨åŠ è½½æ¨¡å‹æ£€æŸ¥ç‚¹: {model_path}")
        data = torch.load(model_path, map_location=device)
        # ç›´æ¥åŠ è½½æ¨¡å‹çš„çŠ¶æ€å­—å…¸
        diffusion_model.load_state_dict(data['model'])
        print("æ¨¡å‹æƒé‡åŠ è½½æˆåŠŸã€‚")
    except FileNotFoundError:
        print(f"ğŸ›‘ é”™è¯¯: æ¨¡å‹æ–‡ä»¶ '{model_path}' æœªæ‰¾åˆ°ã€‚æµ‹è¯•ä¸­æ­¢ã€‚")
        return
    except Exception as e:
        print(f"ğŸ›‘ åŠ è½½æ¨¡å‹æ—¶å‡ºé”™: {e}ã€‚æµ‹è¯•ä¸­æ­¢ã€‚")
        return

    # 4. è¿è¡Œé‡‡æ ·
    diffusion_model.eval()  # åˆ‡æ¢åˆ°è¯„ä¼°æ¨¡å¼

    print("\n--- å¼€å§‹é‡‡æ ·è¿‡ç¨‹ ---")
    # è¿è¡Œæ¨¡å‹ç”Ÿæˆé¢„æµ‹ç»“æœ
    T_pred_norm, S_pred_norm = diffusion_model.sample(
        batch_size=test_batch_size,
        x_f_known_T_orig=T_test_batch,  # è¾“å…¥çš„æ˜¯åŸå§‹å°ºåº¦çš„T
        rescaler=rescaler
    )
    print("--- é‡‡æ ·å®Œæˆ ---\n")

    # 5. æ‰‹åŠ¨åå½’ä¸€åŒ–ï¼Œå¾—åˆ°ç‰©ç†å°ºåº¦çš„é¢„æµ‹ç»“æœ
    T_pred = (T_pred_norm.cpu() + 1) * rescaler.cpu() / 2
    S_pred = (S_pred_norm.cpu() + 1) * rescaler.cpu() / 2

    print(f"é¢„æµ‹Tçš„å½¢çŠ¶: {T_pred.shape}")
    print(f"é¢„æµ‹Sçš„å½¢çŠ¶: {S_pred.shape}")

    # 6. ä¿å­˜é¢„æµ‹ç»“æœ
    output_filename = './data/Test_Gen.h5'
    if not os.path.exists('./data'):
        os.makedirs('./data')

    with h5py.File(output_filename, 'w') as f:
        group = f.create_group('Test')
        group.create_dataset('S', data=S_pred.numpy(), dtype='f4')
        group.create_dataset('T', data=T_pred.numpy(), dtype='f4')
    print(f"é¢„æµ‹ç»“æœå·²æˆåŠŸä¿å­˜åˆ°: {output_filename}")


if __name__ == "__main__":
    torch.manual_seed(13)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(13)
    np.random.seed(13)

    config = {
        # æ¨¡å‹å‚æ•°ï¼Œå¿…é¡»ä¸è®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´
        'dim': 64,
        'dim_mults': (1, 2, 4),
        'time_emb_dim': 256,
        'resnet_groups': 8,
        'padding_mode': 'reflect',

        # æ‰©æ•£è¿‡ç¨‹å‚æ•°ï¼Œå¿…é¡»ä¸è®­ç»ƒæ—¶å®Œå…¨ä¸€è‡´
        'timesteps': 1000,
        'beta_schedule': 'cosine',
        'lambda_S_x0': 1.0,
        'freeze_indices_T': (slice(-1, None), slice(25, 39), slice(25, 39)),

        # æµ‹è¯•æ—¶ç”¨åˆ°çš„å‚æ•°
        'use_fp16': 'no',  # æµ‹è¯•æ—¶é€šå¸¸ä¸éœ€è¦æ··åˆç²¾åº¦
        'load_milestone': 20  # è¦åŠ è½½çš„æ¨¡å‹æ£€æŸ¥ç‚¹ç¼–å·
    }

    # æ–‡ä»¶è·¯å¾„
    train_data_path = './data/2D_Diff_Python.h5'
    test_data_path = './data/Test_Data.h5'
    results_folder_path = './results'  # è®­ç»ƒç»“æœï¼ˆæ¨¡å‹.ptæ–‡ä»¶ï¼‰æ‰€åœ¨çš„æ–‡ä»¶å¤¹

    # è®¾ç½®è¦ä»æµ‹è¯•é›†ä¸­å–å¤šå°‘æ ·æœ¬è¿›è¡Œæµ‹è¯•
    num_test_samples = 50

    run_3d_diffusion_test(config, train_data_path, test_data_path, num_test_samples, results_folder_path)